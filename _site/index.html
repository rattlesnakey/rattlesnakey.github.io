<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->





<title>Hengyuan Zhang (å¼ æ’æº)çš„ä¸»é¡µ</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Hengyuan Zhang (å¼ æ’æº)">
<meta property="og:title" content="Hengyuan Zhang (å¼ æ’æº)">


  <link rel="canonical" href="http://localhost:4000/">
  <meta property="og:url" content="http://localhost:4000/">



  <meta property="og:description" content="Masterâ€™s student at Tsinghua University. Focusing on domain-specific studies in NLP and data mining.">









<!-- end SEO -->

<meta name="google-site-verification" content="fQZQD0EwLaSOrp3EbALt2rjxHEY9pUvWuh1fS96xgNk" />
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="assets/css/main.css">

<meta http-equiv="cleartype" content="on">
<head>
  <base target="_blank">
</head>
    <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/iron-man.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/iron-man.png">
<link rel="manifest" href="images/site.webmanifest">

<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item">
            <a href="https://rattlesnakey.github.io/" target="_self">
              <img class="svg" src="/images/en.svg" width="20pt"> 
              Homepage
            </a>
          </li>
          
            <li class="masthead__menu-item"><a href="/#about-me">About Me</a></li>
          
            <li class="masthead__menu-item"><a href="/#-pub">Publications</a></li>
          
            <li class="masthead__menu-item"><a href="/#-intern">Internships</a></li>
          
            <li class="masthead__menu-item"><a href="/#-honor">Honors and Awards</a></li>
          
            <li class="masthead__menu-item"><a href="/#-miscellaneous">Miscellaneous</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div id="main" role="main">
      
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person" class="profile_box">

  <div class="author__avatar">
    <img src="images/personal-image2.jpg" class="author__avatar" alt="Hengyuan Zhang (å¼ æ’æº)">
  </div>

  <div class="author__content">
    <h3 class="author__name">Hengyuan Zhang (å¼ æ’æº)</h3>
    <p class="author__bio">Tsinghua University</p>
  </div>

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">More Info & Contact</button> -->
    <ul class="author__urls social-icons">
      
        <li><div style="white-space: normal; margin-bottom: 1em;">Master's student at Tsinghua University. Focusing on domain-specific studies in NLP and data mining.</div></li>
      
      
      
      
      
        <li><a href="mailto:zhang-hy22@mails.tsinghua.edu.cn"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
      
      
      
        <li><a href="https://www.linkedin.com/in/hengyuanzhang88/"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
      
      
        <li><a href="https://github.com/rattlesnakey"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
      <div class="author__urls_sm">
      
      
        <a href="mailto:zhang-hy22@mails.tsinghua.edu.cn"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a>
      
      
       
      
      
      
      
        <a href="https://www.linkedin.com/in/hengyuanzhang88/"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i></a>
      
      
      
      
      
      
      
        <a href="https://github.com/rattlesnakey"><i class="fab fa-fw fa-github" aria-hidden="true"></i></a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </div>
  </div>
</div>

  
  </div>

    
      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        <meta itemprop="headline" content="">
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">
            
<p><span class="anchor" id="about-me"></span></p>

<p>ğŸ¤“ Hey folks! I am Hengyuan Zhang (å¼ æ’æº in Chinese). Before going to college, I grew up in Xiamen, a beautiful coastal city in China.</p>

<p>Currently, I am a masterâ€™s student (3rd year) at Tsinghua University under the supervision of Prof. <a href="https://www.semanticscholar.org/author/Yong-Jiang/101321464">Yong Jiang</a> and Prof. <a href="https://scholar.google.com/citations?user=4gH3sxsAAAAJ&amp;hl=zh-CN">Yujiu Yang</a>.</p>

<p>ğŸ“š My research interests revolve around the application of <strong>Natural Language Processing (NLP)</strong> and <strong>Data Mining</strong> in specialized domains such as <em>Multilingualism</em>, <em>Education</em>, and <em>Cognitive Science</em>. I aim to approach these studies in an <strong>interpretable</strong> manner, seeking deeper insights into complex phenomena.
I am also particularly intrigued by the decision-making mechanisms integrated within models, eager to unravel their inner workings and enhance transparency.
All in all, I aim to improve the <strong>speciality</strong> and <strong>interpretability</strong> of models, so as to make them more <strong>powerful</strong> and <strong>trustworthy</strong> in real-world applications.</p>

<p>ğŸ“® Looking ahead, I am exploring the possibility of <strong>enrolling in a Ph.D. program for the Fall of 2025</strong>. 
I am also keen on exploring opportunities for collaboration in research or projects. Please do not hesitate to contact me at your convenience.</p>

<p><span class="anchor" id="-pub"></span></p>

<!-- # ğŸ“š Preprint -->

<h1 id="-publications">ğŸ“ Publications</h1>
<!-- \* denotes equal contribution -->

<!-- NAACL 2025 -->
<div class="paper-box"><div class="paper-box-image"><div><div class="badge">Preprint 2024</div><img src="images/ShifCon.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">
    <p><strong>ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework</strong></p>

    <p><code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei</p>

    <table>
      <tbody>
        <tr>
          <td><a href="https://arxiv.org/pdf/2410.19453">[Paper]</a></td>
          <td><a href="https://github.com/rattlesnakey/ShifCon">[Code]</a></td>
          <td><em>Natural Language Processing, Multilingual, Interpretability in Parameter</em></td>
          <td><em>Conference Preprint</em></td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li>This paper aims to enhance the performance of non-dominant languages by projecting their representations into the dominant language space. We pinpoint the optimal layer area for shifting representations via a subspace distance metric. <span style="color:red">(OpenReview Score: [4, 4, 4.5])</span></li>
    </ul>

  </div>
</div>

<!-- ACL 2024 -->
<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ACL 2024</div><img src="images/CoFiTune.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">
    <p><strong>Balancing Speciality and Versatility: a Coarse to Fine Framework for Supervised Fine-tuning Large Language Model</strong></p>

    <p><code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Yanru Wu, Dawei Li, Zacc Yang, Rui Zhao, Yong Jiang, Fei Tan
<!-- `Hengyuan Zhang`, et al --></p>

    <table>
      <tbody>
        <tr>
          <td><a href="https://arxiv.org/pdf/2404.10306.pdf">[Paper]</a></td>
          <td><a href="https://github.com/rattlesnakey/CoFiTune">[Code]</a></td>
          <td><em>Natural Language Processing, Fine-tuning Technique, Interpretability in Parameter</em></td>
          <td><em>CCF-A Conference</em></td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li>This paper introduces a Coarse-to-Fine Fine-tuning framework (<em>CoFiTune</em>) that strikes a delicate balance between speciality and versatility. It pinpoints and updates specific modules that are crucial for speciality, while keeping other parameters frozen.</li>
    </ul>
  </div>
</div>

<!-- TKDD -->
<div class="paper-box"><div class="paper-box-image"><div><div class="badge">TKDD 2024</div><img src="images/Q-MCKT.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">
    <p><strong>A Question-centric Multi-experts Contrastive Learning Framework for Improving the Accuracy and Interpretability of Deep Sequential Knowledge Tracing Models</strong></p>

    <p><code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Zitao Liu, Chenming Shang, Dawei Li, Yong Jiang</p>

    <table>
      <tbody>
        <tr>
          <td><a href="https://arxiv.org/pdf/2403.07322.pdf">[Paper]</a></td>
          <td><a href="https://github.com/rattlesnakey/Q-MCKT">[Code]</a></td>
          <td><em>Data Mining, Education Recommendation, Interpretability in Prediction</em></td>
          <td><em>JCR Q1 Journal</em></td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li>This paper proposes Q-MCKT framework, which utilizes an item response theory-based prediction layer to generate interpretable prediction results by simultaneously modeling knowledge acquisition and question difficulty.</li>
    </ul>
  </div>
</div>

<!-- NAACL 2025-2 -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint 2024</div><img src='images/BPO.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">NAACL 2025</span>
 <strong>BPO: Towards Balanced Preference Optimization between Knowledge Breadth and Depth in Alignment</strong><br />
Sizhe Wang, Yongqi Tong, <code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Dawei Li, Xin Zhang, Tianlong Chen <br />
<a href="https://arxiv.org/pdf/2411.10914">[Paper]</a> | <em>Natural Language Processing, Fine-tuning Technique</em> | <em>CCF-B Conference</em></li>
</ul>

<!-- ACL 2025 -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint 2024</div><img src='images/LoReKT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">Preprint 2025</span>
 <strong>Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective</strong> <br />
Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, <code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, et al., Yujiu Yang, Furu Wei<br />
<a href="https://arxiv.org/pdf/2501.11110">[Paper]</a> | <em>Natural Language Processing, Fine-tuning Technique</em> | <em>Conference Preprint</em></li>
</ul>

<!-- TKDE -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint 2024</div><img src='images/LoReKT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">Preprint 2024</span>
 <strong>Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning</strong><br />
<code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Zitao Liu, Shuyan Huang, Chenming Shang, Bojun Zhan, Yong Jiang<br />
<a href="https://arxiv.org/pdf/2403.06725.pdf">[Paper]</a> | <a href="https://anonymous.4open.science/r/LoReKT-C619/README.md">[Code]</a> | <em>Data Mining, Education Recommendation</em> | <em>Journal Preprint</em></li>
</ul>

<!-- ICLR 2025 -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint 2024</div><img src='images/LoReKT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">Preprint 2024</span>
 <strong>Compositional Generalization Through Neuroscience-inspired Geometric Constraints on Representation Structure</strong><br />
Chenming Shang, Shiji Zhou, <code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Xinchen Zhang, Lei Ke, Yuwang Wang, Yujiu Yang<br />
<a href="https://ns7kunkhuh.feishu.cn/file/EI8jb6luDoiDQUxYosVc2q3enGd?from=from_copylink">[Paper]</a> | <em>Computer Vision, Cognitive Science, Interpretability in Representation</em> | <em>Conference Preprint</em></li>
</ul>

<!-- CogSci CBM -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CogSci 2024</div><img src='images/CogSci.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">CogSci 2024</span>
 <strong>Understanding Multimodal Deep Neural Networks: A Concept Selection View</strong><br />
Chenming Shang, <code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Hao Wen, Yujiu Yang<br />
<a href="https://arxiv.org/pdf/2404.08964.pdf">[Paper]</a> | <em>Computer Vision, Cognitive Science, Interpretability in Prediction</em> | <em>CCF-B Conference</em></li>
</ul>

<!-- CVPR Res-CBM -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/Res-CBM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">CVPR 2024</span>
 <strong>Incremental Residual Concept Bottleneck Model</strong><br />
Chenming Shang, Shiji Zhou, <code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Yujiu Yang, Xinzhe Ni, Yuwang Wang<br />
<a href="https://arxiv.org/pdf/2404.08978.pdf">[Paper]</a> | <a href="https://github.com/HelloSCM/Res-CBM">[Code]</a> | <em>Computer Vision, Cognitive Science, Interpretability in Prediction</em> | <em>CCF-A Conference</em></li>
</ul>

<!-- emnlp character -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2023</div><img src='images/emnlp2023-character.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">EMNLP 2023</span>
 <strong>Multi-level Contrastive Learning for Script-based Character Understanding</strong><br />
Dawei Li, <code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Yanran Li, Shiping Yang<br />
<a href="https://arxiv.org/pdf/2310.13231v1.pdf">[Paper]</a> | <a href="https://github.com/David-Li0406/Script-based-Character-Understanding">[Code]</a> | <em>Natural Language Processing, Cognitive Science</em> | <em>CCF-B Conference</em></li>
</ul>

<!-- ACL BEA workshop -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2023 BEA</div><img src='images/prompt-contrast-def-gen.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">ACL 2023 BEA</span>
 <strong>Assisting Language Learners: Automated Trans-Lingual Definition Generation via Contrastive Prompt Learning</strong><br />
<code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Dawei Li, Yanran Li, Chenming Shang, Chufan Shi, Yong Jiang<br />
<a href="https://arxiv.org/abs/2306.06058">[Paper]</a> | <a href="https://github.com/rattlesnakey/Prompt-Contrastive-Def-Gen">[Code]</a> | <em>Natural Language Processing, Education, Interpretability in Representation</em> | <em>CCF-A Conference</em></li>
</ul>

<!-- AACL 2022 def-gen -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">AACL 2022 Oral</div><img src='images/def-gen-contrast.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">AACL 2022</span><span style="color:red">(Oral)</span>
 <strong>Fine-grained Contrastive Learning for Definition Generation</strong><br />
<code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Dawei Li, Shiping Yang, Yanran Li<br />
<a href="https://arxiv.org/abs/2210.00543">[Paper]</a> | <a href="https://github.com/rattlesnakey/Definition-Gneration-Contrastive">[Code]</a> | <em>Natural Language Processing, Education, Interpretability in Representation</em> | <em>CCF-A Conference</em></li>
</ul>

<!-- - <span style="background-color:rgba(2,34,141);color:white">AACL 2022</span><span style="color:red">(Oral)</span>
**Fine-grained Contrastive Learning for Definition Generation**\\ 
`Hengyuan Zhang`, Dawei Li, Shiping Yang, Yanran Li\\
[[Paper]](https://arxiv.org/abs/2210.00543) | [[Code]](https://github.com/rattlesnakey/Definition-Gneration-Contrastive) | *Natural Language Processing, Education, Interpretability in Representation* | *Conference* -->

<!-- ACL 2022 multitask -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2022</div><img src='images/multitask-def-gen.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">ACL 2022</span>
 <strong>Multitasking Framework for Unsupervised Simple Definition Generation</strong><br />
Cunliang Kong,Â Yun Chen, <code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Liner Yang, Erhong Yang<br />
<a href="https://arxiv.org/abs/2203.12926">[Paper]</a> | <a href="https://github.com/blcuicall/SimpDefiner">[Code]</a> | <em>Natural Language Processing, Education, Interpretability in Representation</em> | <em>CCF-A Conference</em></li>
</ul>

<!-- NAACL SemEval -->
<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">NAACL 2022 SemEval</div><img src='images/semeval.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->
<ul>
  <li><span style="background-color:rgba(2,34,141);color:white">NAACL 2022 SemEval</span>
 <strong>SemEval-2022 Task 1: Cross-Attention Multitasking Framework for Definition Modeling</strong><br />
Cunliang Kong,Â Yujie Wang, Ruining Chong, Liner Yang, <code class="language-plaintext highlighter-rouge">Hengyuan Zhang</code>, Erhong Yang<br />
<a href="https://arxiv.org/abs/2204.07701">[Paper]</a> | <a href="https://github.com/blcuicall/SemEval2022-Task1-DM">[Code]</a> | <em>Natural Language Processing, Education, Interpretability in Representation</em> | <em>CCF-B Conference</em></li>
</ul>

<p><span class="anchor" id="-intern"></span></p>
<h1 id="-interships">ğŸ’» Interships</h1>
<!-- icall -->
<!-- <img class="svg" src="/images/icall.png" width="60pt">Advanced Innovation Center for Language Resources, Beijing 
<br>
- *Mar. 2019 - Oct. 2021*, Research Assistant, working with [Cunliang Kong](https://scholar.google.com/citations?hl=zh-CN&user=XMkdWRwAAAAJ&view_op=list_works&sortby=pubdate) and [Liner Yang](https://tianlinyang.github.io/index_en.html) -->

<!-- baidu -->
<!-- <img class="svg" src="/images/baidu.png" width="60pt">Baidu, Search Strategy Lab, Beijing
<br>
- *Mar. 2021 - Jul. 2021*, Engineering Intern, working with Ge Chen -->

<!-- <br> -->
<!-- xiaomi -->
<p><img class="svg" src="/images/xiaomi-logo.png" width="30pt" /> Xiaomi, AI Lab, Beijing
<br /></p>
<ul>
  <li><em>Mar. 2022 - Sept. 2022</em>, Research Intern, working with Tong Chen and <a href="https://scholar.google.com/citations?user=URdBBQUAAAAJ&amp;hl=zh-CN">Yanran Li</a></li>
</ul>

<!-- <br> -->
<!-- tencent -->
<p><img class="svg" src="/images/tencent.png" width="70pt" /> Tencent, AI Lab, Shenzhen
<br /></p>
<ul>
  <li><em>Mar. 2023 - Jul. 2023</em>, Research Intern, working with <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=aSJcgQMAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Wei Bi</a></li>
</ul>

<!-- <br> -->
<!-- sensetime -->
<p><img class="svg" src="/images/sensetime.png" width="85pt" />Sensetime, Research, Shenzhen
<br /></p>
<ul>
  <li><em>Aug. 2023 - Mar. 2024</em>, Research Intern, working with <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=IhYATC0AAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Fei Tan</a>
<!-- <br> --></li>
</ul>

<!--MSRA -->
<p><img class="svg" src="/images/MSRA.png" width="60pt" />Microsoft Research Asia, Natural Language Computing (NLC) Group, Beijing
<br /></p>
<ul>
  <li><em>Mar. 2024 - Dec. 2024</em>, Research Intern, working with <a href="https://scholar.google.com/citations?user=w2qu71oAAAAJ&amp;hl=en">DongDong Zhang</a>
    <ul>
      <li>I got the <span style="color:red">â€œMicrosoft Stars of Tomorrowâ€</span> Award during the internship</li>
    </ul>
  </li>
</ul>

<!-- <br> -->

<p><br />
<span class="anchor" id="-honor"></span></p>

<h1 id="-selected-honors-and-awards">ğŸ… Selected Honors and Awards</h1>
<p>ğŸ‘‰Â  Tsinghua University Comprehensive First-Class Scholarship (Top 3%, RMB Â¥ 10,000) | <em>2024</em></p>

<p>ğŸ‘‰Â  Tsinghua University General Excellence Scholarship (Top 5%, RMB Â¥ 4,000) | <em>2023</em></p>

<p>ğŸ‘‰Â  National Scholarship (Top 1%, RMB Â¥ 8,000) | <em>2019, 2020, 2021</em></p>

<p>ğŸ‘‰Â  Outstanding Graduate Student of Beijing (Top 3%) | <em>2022</em></p>

<p>ğŸ‘‰Â  Excellent League Member of Beijing (Top 3%) | <em>2021</em></p>

<p>ğŸ‘‰Â  Merit Student of Beijing (Top 3%) | <em>2021</em></p>

<p>ğŸ‘‰Â Â Meritorious Winner of Interdisciplinary Contest in Modeling (Top 5%) | <em>2021</em></p>

<p>ğŸ‘‰Â  Computer Design Competition National Second Prize (Top 5%) | <em>2020</em></p>

<p>ğŸ‘‰Â  CUMCM-Beijing Area First Prize (Top 5%) | <em>2020</em></p>

<p>ğŸ‘‰Â  Xiaomi Third Hacker Marathon Excellence (Top 7%, RMB Â¥ 3,000) | <em>2022</em></p>

<!-- <br>
<span class='anchor' id='-miscellaneous'></span>
# â›³ï¸ Extracurricular Activities
- Vice Minister of the Academic Department, SIGS Student Union, Tsinghua University  -->

<p><br />
<span class="anchor" id="-miscellaneous"></span></p>
<h1 id="-miscellaneous">ğŸ“Œ Miscellaneous</h1>
<ul>
  <li>I once led the Academic Department of SIGS Student Union at Tsinghua University. During which, I organized academic activities such as academic forums and experience-sharing sessions. I am also a member of the Beijing Xiamen ECC (åŒ—äº¬å¦é—¨ä¼ä¸šå•†ä¼š), actively participating in sharing activities <a href="https://mp.weixin.qq.com/s/DFG97r0-hL12VYFAeshpHA">[Link]</a>.</li>
  <li>I also participated in social activities such as rural revitalization <a href="images/fuding.jpg">[Photo]</a>, representing Tsinghua in a Swiss â€œGlobal Warmingâ€ forum <a href="images/swiss.jpg">[Photo]</a>, and helping international students with Chinese, computer, and math <a href="images/tutoring.jpg">[Photo]</a>.</li>
  <li>I am actually a person with a strong desire to share. In my spare time, I like writing blogs and sharing experiences on Redbook, <a href="https://mp.weixin.qq.com/mp/profile_ext?action=home&amp;__biz=Mzk0NTI3ODI2OQ==&amp;scene=124#wechat_redirect">Wechat Official Account</a>, and <a href="https://space.bilibili.com/14709944?spm_id_from=333.1007.0.0">Bilibili</a> (é˜¿æºçš„NLPç¢ç¢å¿µ). The selected blogs are as follows:
    <ul>
      <li><a href="https://mp.weixin.qq.com/s/D4z8zHmr3cij5_d5rOgLwg">Interpreting Arithmetic Calculation Modules within LLMs</a></li>
      <li><a href="https://mp.weixin.qq.com/s/3693Q7NPnRoH0r4S0RiEDA?token=889452301&amp;lang=zh_CN">Interpreting Security Modules within Large Language Model</a></li>
      <li><a href="https://mp.weixin.qq.com/s/8EB1q8w9DmIw_M7msK_cgw?token=889452301&amp;lang=zh_CN">Do Llama Work in English?</a></li>
      <li><a href="https://mp.weixin.qq.com/s/-FHKqUieqJuO3VoTozS4Mw">Interpreting Linguistic Regions with in LLMs</a></li>
      <li><a href="https://mp.weixin.qq.com/s/udjiYzt7cwCdlH1a98ylbA">Prevent Catastrophic Forgetting via SoftMask Mechanism</a></li>
      <li><a href="https://mp.weixin.qq.com/s/hXMEQ7ZPF53-iyOzZRXXZg">The Key Components in Transformer</a></li>
      <li><a href="https://mp.weixin.qq.com/s/m3RHJ9q-RCkGL33AewdDUg">The Evaluation of Instruction Following</a></li>
      <li><a href="https://mp.weixin.qq.com/s/x61tHD896Leoz8DO-0weAg">Skill Localization of Large Language Model</a></li>
      <li><a href="https://mp.weixin.qq.com/s/fQ6t96aqAgvRDAIjIt9QYA">iMAge-guided Text GeneratIon with CLIP</a></li>
    </ul>
  </li>
  <li>I used to be a guitarist ğŸ¸Â in a band when I was in high school. Also, I love playing badminton ğŸ¸, table tennis ğŸ“Â and, soccer âš½ï¸. During holidays, I will also seize any opportunity to travel around the world  â›³ï¸.</li>
</ul>

<div style="display: flex;">
  <img src="images/life1.png" alt="Image 1" width="50%" />
  <img src="images/life3.png" alt="Image 2" width="50%" />
</div>

<p><br /></p>

<div style="display: flex;">
  <img src="images/life2.png" alt="Image 1" width="50%" />
  <img src="images/life4.png" alt="Image 2" width="50%" />
</div>

<!-- <span class='anchor' id='-posts'></span>

# ğŸ“œ Selected Posts -->


          </section>
        </div>
      </article>
    </div>

    <script src="assets/js/main.min.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FNMFPMMGS6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "G-FNMFPMMGS6");
</script>


<script>
    $(document).ready(function () {
        
        var gsDataBaseUrl = 'https://raw.githubusercontent.com/rattlesnakey/rattlesnakey.github.io/'
        
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {
            var totalCitation = data['citedby']
            document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = '| Citations: ' + numCitations;
            });
        });
    })
</script>


<div class="footer_site">
<hr/>
<!-- <div class="footer_copyright">
  Â© 2022 åä¸­å¤§ Â· å”å¥ | åŸºäº&nbsp
  <a class="page_a"  href="https://github.com/RayeRen/acad-homepage.github.io">
  acad
  </a>&nbspæ¨¡æ¿
</div> -->
</div>
  </body>
</html>
